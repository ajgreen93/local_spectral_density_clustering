\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts, amsthm, amssymb}
\usepackage{graphicx}
\usepackage[colorlinks]{hyperref}
\usepackage[parfill]{parskip}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{fullpage}

\usepackage{natbib}
\renewcommand{\bibname}{REFERENCES}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

\newcommand{\eqdist}{\ensuremath{\stackrel{d}{=}}}
\newcommand{\Graph}{\mathcal{G}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Identity}{\mathbb{I}}
\newcommand{\distiid}{\overset{\text{i.i.d}}{\sim}}
\newcommand{\convprob}{\overset{p}{\to}}
\newcommand{\convdist}{\overset{w}{\to}}
\newcommand{\Expect}[1]{\mathbb{E}\left[ #1 \right]}
\newcommand{\Risk}[2][P]{\mathcal{R}_{#1}\left[ #2 \right]}
\newcommand{\Prob}[1]{\mathbb{P}\left( #1 \right)}
\newcommand{\iset}{\mathbf{i}}
\newcommand{\jset}{\mathbf{j}}
\newcommand{\myexp}[1]{\exp \{ #1 \}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left \lvert #1 \right \rvert}
\newcommand{\restr}[2]{\ensuremath{\left.#1\right|_{#2}}}
\newcommand{\ext}[1]{\widetilde{#1}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\seq}[1]{\set{#1}_{n \in \N}}
\newcommand{\dotp}[2]{\langle #1, #2 \rangle}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\diam}{\mathrm{diam}}

\newcommand{\emC}{C_n}
\newcommand{\emCpr}{C'_n}
\newcommand{\emCthick}{C^{\sigma}_n}
\newcommand{\emCprthick}{C'^{\sigma}_n}
\newcommand{\emS}{S^{\sigma}_n}
\newcommand{\estC}{\widehat{C}_n}
\newcommand{\hC}{\hat{C^{\sigma}_n}}
\newcommand{\vol}{\text{vol}}
\newcommand{\spansp}{\mathrm{span}~}
\newcommand{\1}{\mathbf{1}}

\newcommand{\Linv}{L^{\dagger}}

\DeclareMathOperator*{\argmax}{argmax}

\newcommand{\emF}{\mathbb{F}_n}
\newcommand{\emG}{\mathbb{G}_n}
\newcommand{\emP}{\mathbb{P}_n}
\newcommand{\F}{\mathcal{F}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\Rd}{\Reals^d}

%%% Data
\newcommand{\Xbf}{X}

%%% Vectors
\newcommand{\thetast}{\theta^{\star}}

%%% Matrices
\newcommand{\X}{X} % no bold
\newcommand{\Y}{Y} % no bold
\newcommand{\Z}{Z} % no bold
\newcommand{\Lgrid}{L_{\grid}}
\newcommand{\Dgrid}{D_{\grid}}
\newcommand{\Linvgrid}{L_{\grid}^{\dagger}}

%%% Sets and classes
\newcommand{\Xset}{\mathcal{X}}
\newcommand{\Sset}{\mathcal{S}}
\newcommand{\Cset}{\mathcal{C}}
\newcommand{\Csig}{\Cset_{\sigma}}
\newcommand{\Hclass}{\mathcal{H}}
\newcommand{\Pclass}{\mathcal{P}}

%%% Distributions and related quantities
\newcommand{\Pbb}{\mathbb{P}}
\newcommand{\Ebb}{\mathbb{E}}
\newcommand{\Qbb}{\mathbb{Q}}

%%% Vector spaces
\newcommand{\Zbb}{\mathbb{Z}}

%%% Operators
\newcommand{\Tadj}{T^{\star}}
\newcommand{\dive}{\mathrm{div}}
\newcommand{\dif}{\mathop{}\!\mathrm{d}}
\newcommand{\gradient}{\mathcal{D}}
\newcommand{\Hessian}{\mathcal{D}^2}

%%% Misc
\newcommand{\grid}{\mathrm{grid}}
\newcommand{\critr}{R_n}
\newcommand{\dx}{\,dx}
\newcommand{\dy}{\,dy}
\newcommand{\dr}{\,dr}
\newcommand{\wt}[1]{\widetilde{#1}}

%%% Order of magnitude
\newcommand{\soom}{\sim}

% \newcommand{\span}{\textrm{span}}

\newtheoremstyle{alden}
{6pt} % Space above
{6pt} % Space below
{} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{alden} 


\newtheoremstyle{aldenthm}
{6pt} % Space above
{6pt} % Space below
{\itshape} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{aldenthm}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}

\begin{document}
\title{Notes for 9/16/19 - 9/20/19}
\author{Alden Green}
\date{\today}
\maketitle

In the local spectral density clustering problem, one observes data $x_1,\ldots,x_n$ sampled independently from a density function $f$ supported on $\mathcal{X}$. Letting $\Cset$ be a connected component of the upper level set $\set{x:f(x) > \lambda}$, since we observe a finite sample we can only hope to recover $\Csig = \Cset + B(0,\sigma)$ for some $\sigma > 0$. Our strategy will be to
\begin{itemize}
	\item Form a neighborhood graph $G_{n,r}$ by connecting points at scale $r$ (i.e. using the kernel function $\1(\norm{x - y} \leq r)$. 
	\item Operate in some manner on the neighborhood graph $G_{n,r}$ to form a cluster estimate $\hat{C}$. 
\end{itemize}

This week, we focus on lower bounds for the density clustering problem. To begin, let's detail the various lower bounds one might hope to prove (roughly in order from weakest to strongest.) In the following, $\Sset[\Xbf]$ will always be a set with high symmmetric set difference metric to $\Csig[\Xbf]$. For example, assume $\Delta(\Sset[\Xbf],\Csig[\Xbf]) \geq 1/8$ with high probability as $n \to \infty$. All but the last lower bound are inconsistency statements for various classes of algorithms; the last lower bound is a statement regarding sample complexity.
\begin{enumerate}
	\item There exists some $\Sset \subset \mathcal{X}$ such that if you perform PPR over $G_{n,r}$, and tune hyperparameters appropriately for $\Sset$, with high probability you will recover $\Sset[\Xbf]$ as $n \to \infty$. 
	
	\item There exists some $\Sset \subset \mathcal{X}$ such that if you perform PPR over $G_{n,r}$, and tune hyperparameters appropriately for $\Csig$, with high probability you will recover $\Sset[\Xbf]$ as $n \to \infty$. 
	
	\item If you perform PPR over $G_{n,r}$ with $r$ tuned appropriately for $\Csig$, for any choice of hyperparameters $v, \alpha$ and $\pi_0$, with high probability you will recover some $\Sset_{(v,\alpha,\pi_0)}[\Xbf]$ as $n \to \infty$. 
	
	\item If you perform PPR over $G_{n,r}$ for any choice of hyperparameters $r, v, \alpha$ and $\pi_0$, with high probability you will recover some $\Sset_{(r, v,\alpha,\pi_0)}[\Xbf]$ as $n \to \infty$. 
	
	\item If you perform any spectral algorithm over $G_{n,r}$, you will fail to recover $\Csig[\Xbf]$ as $n \to \infty$. 
	
	\item For a fixed $n$ and for any $r > 0$, any algorithm operating on $G_{n,r}$ will have $\Delta(\widehat{C}, \Csig[\Xbf]) > \eta$ for some critical radius $\eta$ which may depend on $n$ and $r$. 
\end{enumerate}

The first lower bound is very weak, and we do not investigate it further. We include it merely to note that the strategy of applying an upper bound on PPR misclassification error to an appropriately chosen $\Sset \subset \Xset$ would result in this type of weak lower bound. Our lower bound will therefore require at least in part different proof techniques than the one we use for our upper bound.

\section{PPR with any hyperparameters.}


\section{Any spectral algorithm.}

Note: this section will be consistent in spirit, but not in technical details, with the problem as introduced previously. 

Let $K(x,y)$ be a positive semi-definite kernel function in $\Rd$. 


\end{document}