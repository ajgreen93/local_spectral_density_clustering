\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts, amsthm, amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[colorlinks]{hyperref}
\usepackage[parfill]{parskip}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{enumerate}
\usepackage{fullpage}

\usepackage{natbib}
\renewcommand{\bibname}{REFERENCES}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

\makeatletter
\newcommand{\leqnomode}{\tagsleft@true}
\newcommand{\reqnomode}{\tagsleft@false}
\makeatother

\newcommand{\eqdist}{\ensuremath{\stackrel{d}{=}}}
\newcommand{\Graph}{\mathcal{G}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Identity}{\mathbb{I}}
\newcommand{\distiid}{\overset{\text{i.i.d}}{\sim}}
\newcommand{\convprob}{\overset{p}{\to}}
\newcommand{\convdist}{\overset{w}{\to}}
\newcommand{\Expect}[1]{\mathbb{E}\left[ #1 \right]}
\newcommand{\Risk}[2][P]{\mathcal{R}_{#1}\left[ #2 \right]}
\newcommand{\Var}[1]{\mathrm{Var}\left( #1 \right)}
\newcommand{\Prob}[1]{\mathbb{P}\left( #1 \right)}
\newcommand{\iset}{\mathbf{i}}
\newcommand{\jset}{\mathbf{j}}
\newcommand{\myexp}[1]{\exp \{ #1 \}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\dotp}[2]{\langle #1 , #2 \rangle}
\newcommand{\abs}[1]{\left \lvert #1 \right \rvert}
\newcommand{\restr}[2]{\ensuremath{\left.#1\right|_{#2}}}
\newcommand{\defeq}{\overset{\mathrm{def}}{=}}
\newcommand{\convweak}{\overset{w}{\rightharpoonup}}
\newcommand{\dive}{\mathrm{div}}
\newcommand{\Bin}{\mathrm{Bin}}

\newcommand{\emC}{C_n}
\newcommand{\emCpr}{C'_n}
\newcommand{\emCthick}{C^{\sigma}_n}
\newcommand{\emCprthick}{C'^{\sigma}_n}
\newcommand{\emS}{S^{\sigma}_n}
\newcommand{\estC}{\widehat{C}_n}
\newcommand{\hC}{\hat{C^{\sigma}_n}}
\newcommand{\Bal}{\textrm{Bal}}
\newcommand{\Cut}{\textrm{Cut}}
\newcommand{\Ind}{\textrm{Ind}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\seq}[1]{\set{#1}_{n \in \N}}
\newcommand{\Perp}{\perp \! \! \! \perp}
\newcommand{\Naturals}{\mathbb{N}}
\newcommand{\dist}{\mathrm{dist}}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}


\newcommand{\Linv}{L^{\dagger}}
\newcommand{\tr}{\text{tr}}
\newcommand{\h}{\textbf{h}}
% \newcommand{\l}{\ell}
\newcommand{\x}{\textbf{x}}
\newcommand{\y}{\textbf{y}}
\newcommand{\bl}{\bm{\ell}}
\newcommand{\bnu}{\bm{\nu}}
\newcommand{\Lx}{\mathcal{L}_X}
\newcommand{\Ly}{\mathcal{L}_Y}
\DeclareMathOperator*{\argmin}{argmin}


\newcommand{\emG}{\mathbb{G}_n}
\newcommand{\A}{\mathcal{A}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Rd}{\Reals^d}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathcal{E}}

%%% Matrix related notation
\newcommand{\Xbf}{\mathbf{X}}
\newcommand{\Ybf}{\mathbf{Y}}
\newcommand{\Zbf}{\mathbf{Z}}
\newcommand{\Abf}{\mathbf{A}}
\newcommand{\Dbf}{\mathbf{D}}
\newcommand{\Wbf}{\mathbf{W}}
\newcommand{\Lbf}{\mathbf{L}}
\newcommand{\Ibf}{\mathbf{I}}
\newcommand{\Bbf}{\mathbf{B}}

%%% Vector related notation
\newcommand{\lbf}{\bm{\ell}}
\newcommand{\fbf}{\mathbf{f}}

%%% Set related notation
\newcommand{\Cset}{\mathcal{C}}
\newcommand{\Dset}{\mathcal{D}}
\newcommand{\Aset}{\mathcal{A}}
\newcommand{\Wset}{\mathcal{W}}
\newcommand{\Sset}{\mathcal{S}}

\newcommand{\Csig}{\Cset_{\sigma}}
\newcommand{\Asig}{\Aset_{\sigma}}

%%% Distribution related notation
\newcommand{\Pbb}{\mathbb{P}}
\newcommand{\Qbb}{\mathbb{Q}}
\newcommand{\Ebb}{\mathbb{E}}
% \newcommand{\Pr}{\mathrm{Pr}}}

%%% Functionals
\newcommand{\1}{\mathbf{1}}

%%% Functionals over graphs
\newcommand{\cut}{\mathrm{cut}}
\newcommand{\vol}{\mathrm{vol}}
% \newcommand{\deg}{\mathrm{deg}}

\newtheoremstyle{alden}
{6pt} % Space above
{6pt} % Space below
{} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{alden} 
\newtheorem{definition}{Definition}[section]

\newtheoremstyle{aldenthm}
{6pt} % Space above
{6pt} % Space below
{\itshape} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{aldenthm}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\begin{document}
	
\title{Notes for the week of 4/27/19 - 5/3/19}
\author{Alden Green}
\date{\today}
\maketitle

Let $\Aset \subseteq \Reals^d$, and for $\sigma \geq 0$, write $\sigma B := B(0,\sigma) = \set{x \in \Rd: \norm{x} \leq \sigma}$ for the closed ball of radius $\sigma$ centered at the origin (and let $B^{\circ}(0,\sigma)$ denote the corresponding open ball). Let $\Asig = \Aset + \sigma B$ be the direct sum of $\Aset$ and $\sigma B$.

\begin{theorem}
	\label{thm: expansion_volume}
	If $\Aset$ is closed and bounded, then for any $\delta > 0$,
	\begin{equation*}
	\nu(\Asig + \delta B) \leq \left(1 + \frac{\delta}{\sigma}\right)^d \nu(\Asig).
	\end{equation*}
\end{theorem}
\begin{proof}
	We will show that for any $\epsilon > 0$, 
	\begin{equation}
	\label{eqn: ratio_of_volume}
	\frac{\nu(\Asig + \delta B)}{\nu(\Asig)} \leq \frac{(\sigma + \delta + \epsilon)^d}{\sigma^d}
	\end{equation}
	which is sufficient to prove the claim.
	
	
	Fix $\epsilon > 0$. Our first goal is to find a finite collection $x_1, \ldots, x_N \in \Rd$ such that
	\begin{equation*}
	\bigcup_{i = 1}^{N} B(x_i, \sigma) \subseteq \Asig \subset \bigcup_{i = 1}^{N} B(x_i, \sigma + \epsilon). \tag{$N := N(\epsilon)$}
	\end{equation*}
	
	Observe that since $\Aset$ is closed and bounded, it is compact. As $B(x,\sigma)$ is compact, and the direct sum of two compact sets is itself compact, $\Asig$ is compact. Moreover,
	\begin{equation*}
	\Asig \subset \bigcup_{x \in \Aset} B^{\circ}(x,\sigma + \epsilon)
	\end{equation*}
	so by compactness there exists $x_1, \ldots,x_N \in \Aset$ such that
	\begin{equation*}
	\Asig \subset \bigcup_{i = 1}^{N} B^{\circ}(x_i,\sigma + \epsilon).
	\end{equation*}
	
	By the triangle inequality, $\Asig + \delta B \subset \bigcup_{i = 1}^{N} B^{\circ}(x_i,\sigma + \epsilon + \delta)$. Of course, for each $x_i \in \Aset$, $B(x_i,\sigma) \in \Asig$. Summarizing our findings, we have
	\begin{equation}
	\label{eqn: finite_subcover}
	\bigcup_{i = 1}^{N} B(x_i,\sigma) \subseteq \Asig  ,~\Asig + \delta B \subset \bigcup_{i = 1}^{N} B^{\circ}(x_i,\sigma + \delta + \epsilon)
	\end{equation}

	We proceed by giving a lower bound on $\nu(\Asig)$. Partition $\Asig$ using the balls $B(x_i,\sigma)$, meaning let $\Aset_{\sigma}^{(1)} := B(x_1,\sigma)$, $\Aset_{\sigma}^{(2)} := B(x_2,\sigma) \setminus B(x_1,\sigma)$, and continuing, so that
	\begin{equation*}
	\Aset_{\sigma}^{(i)} := B(x_i,\sigma) \setminus \bigcup_{j = 1}^{i - 1} \Aset_{\sigma}^{(j)}. \tag{$i = 1,\ldots,N$}
	\end{equation*}
	Of course, by \eqref{eqn: finite_subcover} $\Asig \supseteq \bigcup_{i = 1}^{N} \Asig^{(i)}$. Therefore,
	\begin{align*}
	\nu(\Asig) & \geq \sum_{i = 1}^{N} \nu(\Asig^{(i)}) \\
	& = \sigma^d \nu_d \sum_{i = 1}^{N}  \frac{\nu(\Asig^{(i)})}{\nu(B(x_i,\sigma))} \\
	& =: \sigma^d \nu_d \sum_{i = 1}^{N} c_i.
	\end{align*}
	
	
	Now we turn to proving an upper bound on $\nu(\Asig + \delta B)$. Let $\Aset_{\sigma + \epsilon + \delta}^{(1)} := B(x_1,\sigma + \delta + \epsilon)$ and
	\begin{equation*}
	\Aset_{\sigma + \delta + \epsilon}^{(i)} := B(x_i,\sigma + \delta + \epsilon) \setminus \bigcup_{j = 1}^{i - 1} \Aset_{\sigma + \delta + \epsilon}^{(j)}. \tag{$i = 1,\ldots,N$}
	\end{equation*}
	
	By \eqref{eqn: finite_subcover},
	\begin{equation*}
	\Aset_{\sigma} + \delta B \subset \bigcup_{i =1}^{N} \Aset_{\sigma + \delta + \epsilon}^{(i)}
	\end{equation*}
	and as a result
	\begin{align*}
	\nu(\Aset_{\sigma + \delta}) & \leq \sum_{i = 1}^{N} \Aset_{\sigma + \delta + \epsilon}^{(i)} \\
	& = \sum_{i = 1}^{N} \nu_d (\sigma + \delta + \epsilon)^d \frac{\nu(\Aset_{\sigma + \delta + \epsilon}^{(i)})}{\nu(B(x_i, \sigma + \delta + \epsilon))} \\
	& \leq \nu_d (\sigma + \delta + \epsilon)^d \sum_{i = 1}^{N} c_i
	\end{align*}
	where the last inequality follows from Lemma \ref{lem: covering}. We have shown \eqref{eqn: ratio_of_volume}, and thus the claim.
\end{proof}

\section{Additional Theory}

\begin{lemma}
	\label{lem: covering}
	For $i = 1, \ldots, N$ and  $A_{\sigma}^{(i)}, A_{\sigma + \delta + \epsilon}^{(i)}$ as in Theorem \ref{thm: expansion_volume},
	\begin{equation*}
	\frac{\nu(\Aset_{\sigma + \delta + \epsilon}^{(i)})}{\nu(B(x_i, \sigma + \delta + \epsilon))} \leq \frac{\nu(\Aset_{\sigma}^{(i)})}{\nu(B(x_i, \sigma))}
	\end{equation*}
\end{lemma}
\begin{proof}
	Let $\delta' := \delta + \epsilon$. It will be sufficient to show that
	\begin{equation*}
	\biggl(\Aset_{\sigma + \delta'}^{(i)} - \set{x_i}\biggr) \subseteq \left(1 + \frac{\delta'}{\sigma}\right)\cdot\biggl(\Asig^{(i)} - \set{x_i}\biggr) 
	\end{equation*}
	since then
	\begin{equation*}
	\nu(\Aset_{\sigma + \delta'}^{(i)}) \leq \left(1 + \frac{\delta'}{\sigma}\right)^d \nu(\Aset_{\sigma}) = \frac{\nu(B(x_i, \sigma + \delta'))}{\nu(B(x_i, \sigma))} \nu(\Aset_{\sigma}).
	\end{equation*}
	
	Assume without loss of generality that $x_i = 0$, and let $x \in \Aset_{\sigma + \delta'}^{(i)}$, meaning
	\begin{equation}
	\norm{x} \leq \sigma + \delta',~ \norm{x - x_j} > \sigma + \delta'~ \textrm{for $j = 1, \ldots, i - 1$}.
	\end{equation}
	Letting $x' = \frac{\sigma}{\sigma + \delta'} x$, since $\norm{x} \leq \sigma + \delta'$, $\norm{x'} \leq \sigma$ and therefore $x' \in B(0,\sigma)$. Additionally observe that for any $j = 1, \ldots, i - 1$, by the triangle inequality
	\begin{equation*}
	\norm{x' - x_j} \geq \norm{x - x_j} - \norm{x - x'} > \sigma + \delta' - \frac{\delta'}{\sigma + \delta'}\norm{x} \geq \sigma
	\end{equation*}
	and therefore $x' \not\in B(x_j,\sigma)$ for any $j = 1,\ldots, i - 1$. So $x' \in \Asig^{(i)}$.
\end{proof}

\section{Old version of the same result.}

For two sets $\mathcal{X},\mathcal{Y}$ and scalar $\alpha$, we write 
\begin{equation*}
\mathcal{X} + \mathcal{Y} := \set{z: z = x + y, x \in \mathcal{X}, y \in \mathcal{Y}},~ \mathcal{X} - \mathcal{Y} := \set{z: z = x - y, x \in \mathcal{X}, y \in \mathcal{Y}}
\end{equation*}
and $\alpha \mathcal{X} = \set{z: z = \alpha x, x \in \mathcal{X}}$. 

Let $B = B(0,1)$ be the $d$-dimensional unit ball centered at the origin.

\begin{lemma}
	\label{lem: expansion_sets}
	Let $\mathcal{K} \subseteq \Reals^d$ be a convex set, and $g: \Reals^d \to \Reals^d$ be a measure preserving Lipschitz mapping, meaning there exists $ L > 0$ such that
	\begin{equation*}
	\frac{1}{L} \norm{x - y} \leq \norm{g(x) - g(y)} \leq L \norm{x - y} \tag{for all $x,y \in \Reals^d$}
	\end{equation*}
	and $\norm{\nabla g (x)} = 1$ for all $x \in \Reals^d$. Letting $\mathcal{A} = g(\mathcal{K})$, the following statement holds: if for $\sigma > 0$, there exists some $x \in \Rd$ such that 
	\begin{equation}
	\label{eqn: expansion_sets}
	B(x,\sigma) \subseteq \mathcal{A} 
	\end{equation}
	then for any $\delta > 0$
	\begin{equation*}
	\nu(\mathcal{A} + \delta B) \leq \left(1 + \frac{L^2 \delta}{\sigma}\right)^d \nu(\mathcal{A})
	\end{equation*}
\end{lemma}
\begin{proof}
	We begin by showing the statement in the convex case, where $g = \mathrm{Id}$ is the identity mapping, before proceeding to show it in full generality. Without loss of generality assume $\sigma B \subseteq \mathcal{A}$, otherwise center by $\mathcal{A} - x$ for some $x$ such that $B(x,\sigma) \subseteq \mathcal{A}$, and as Lebesgue measure is invariant under translation any bound on the volume of $\mathcal{A} - x$ holds for $\mathcal{A}$ as well.
	
	\textbf{Convex case, $g = \Id$.}
	
	Note that 
	\begin{equation}
	\label{eqn: expansion_sets_1}
	\mathcal{A} + \delta B \subseteq \mathcal{A} + \frac{\delta}{\sigma}\mathcal{A}
	\end{equation}
	as $y \in \delta B$ implies $\frac{\sigma}{\delta}y \in \sigma B \subseteq \mathcal{A}$. For $z \in \mathcal{A} + \frac{\delta}{\sigma}\mathcal{A}$, write $z := a + \frac{\delta}{\sigma} a'$ for some $a,a' \in \mathcal{A}$. Then
	\begin{equation}
	\label{eqn: expansion_sets_2}
	\frac{1}{1 + \delta/\sigma}z = \frac{1}{1 + \delta/\sigma}a + \frac{\delta/\sigma}{1 + \delta/\sigma} a' \in \mathcal{A}
	\end{equation}
	where the last statement follows by the convexity of $\mathcal{A}$. Together, \eqref{eqn: expansion_sets_1} and \eqref{eqn: expansion_sets_2} imply $\mathcal{A} + \delta B \subseteq (1 + \frac{\delta}{\sigma})\mathcal{A}$, and therefore
	\begin{equation*}
	\nu(\mathcal{A} + \delta B) \leq \nu\Biggl(\left(1 + \frac{\delta}{\sigma}\right)\mathcal{A}\Biggr) = \left(1 + \frac{\delta}{\sigma}\right)^d \nu(\mathcal{A})
	\end{equation*}
	where the last statement follows by the change of variables formula.
	
	\textbf{Non-convex case, $g$ general.} For any $z \in \mathcal{A} + \delta B$, there exists $x \in \mathcal{A}$ such that $\norm{z - x} \leq \delta$. Therefore
	\begin{equation*}
	\norm{g^{-1}(z) - g^{-1}(x)} \leq L \delta
	\end{equation*}
	and since $g^{-1}(x) \in \mathcal{K}$, $g^{-1}(z) \in \mathcal{K} + L \delta B$. As a result, $\mathcal{A} + \delta B \subseteq g(\mathcal{K} + L \delta B)$; since $g$ is measure-preserving, we have
	\begin{equation*}
	\nu(\mathcal{A} + \delta B) \leq \nu(\mathcal{K} + L \delta B)
	\end{equation*}
	
	Additionally, note that the hypothesis $\sigma B \subseteq \mathcal{A}$ implies that $g^{-1}(\sigma B) \subseteq \mathcal{K}$, and if $\norm{z} \leq \frac{\sigma}{L}$, then $g(z) \in \sigma(B)$ and $z \in g^{-1}(\sigma B)$. Therefore, letting $\sigma' = \frac{\sigma}{L}$, we have
	\begin{equation*}
	\sigma' B \subseteq \mathcal{K}
	\end{equation*}
	and the general result follows from applying the convex result to $\mathcal{K} + \delta'B$ for $\delta' = \delta L$. 
\end{proof}

\end{document}