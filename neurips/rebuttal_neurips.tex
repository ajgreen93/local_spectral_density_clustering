\documentclass{article}

\usepackage{neurips_2019_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{lipsum}

\begin{document}
We thank the reviewers for their comments and feedback. We first respond to a common concern among the reviewers, before making individual responses below.


A common critique from reviewers is that the set of assumptions we impose on a given density cluster $\mathcal{C}$ are not sufficiently motivated. 
In the statistical learning setup, it is natural to investigate the extent to which a clustering algorithm identifies ``natural clusters'' of the underlying distribution.
%Our motivation is as follows: on the one hand, a commonly analyzed paradigm in nonparametric clustering is density clustering, and on the other hand many common nonparametric clustering algorithms are spectral in nature. 
Often, spectral clustering algorithms are intuitively thought of as identifying groups of points in connected high-density regions. However, in past theoretical studies of spectral clustering algorithms (such as Shi et al. and Schiebinger et al.), the requirement that a cluster have high density is often implicit in the formally stated assumptions.  A formal assumption of this nature is neither explicitly stated, nor is it sufficient to satisfy the required assumptions in these works. As a result, it is still unclear when, if ever, spectral clustering algorithms do recover high-density clusters. 

Spectral algorithms trade-off different considerations (connectivity and compactness) in a complex way and are able to only recover a subset of geometrically-compact density clusters (our assumptions provide precise quantification to this statement).
In more detail, our work provides conditions on the underlying density and the target density cluster, in order for it to be a good candidate for a spectral algorithm (in our case, \textrm{PPR}). 

%In essence we find that geometrically-compact high-density clusters 

%We start from the same basic premise that a good candidate set $\mathcal{C}$ for recovery by a spectral clustering algorithm should have high density. In our case, however, we restrict $\mathcal{C}$ to have uniformly lower bounded density by requiring it to be an upper-level set of the density function. Our goal is then to detail what \textit{other} properties a cluster should have, in addition to being a high-density set, 

\textbf{Response to Reviewer 1.}

[``Challenges to the proof...''] We agree that more discussion of proof techniques would be useful for the interested reader and we will elaborate on this in our revision. The main two technical contributions of the work are Theorems 3 and 4, upper bounds on normalized cut and mixing time over a neighborhood graph. The main challenge in upper bounding the expected normalized cut is to upper bound the probability mass assigned to $\{x: 0 \leq \mathrm{dist}(x,\mathcal{C}) \leq r\}$, as all edges which cross the cut $\mathrm{cut}(\mathcal{C}_{\sigma}[X]; G_{n,r})$ must have (exactly) one endpoint in this set. Then, passing from an upper bound on expected normalized cut to a finite-sample bound is relatively straightforward. Upper bounding mixing time of a random walk over $\mathcal{C}_{\sigma}[X]$ is less straightforward, as it requires a \textit{uniform} lower bound on the normalized cut of subsets of $\mathcal{C}_{\sigma}[X]$. We invoke population-level results to lower bound the conductance (minimum normalized cut) of subsets of $\mathcal{C}_{\sigma}$, then rely on optimal transportation theory to relate this bound to a bound on the conductance of $\mathcal{C}_{\sigma}[X]$.

[``What type of distributional properties needed...''] We agree adding common examples would help clarify the significance of our contribution. The common nonparametric mixture model most suited to our assumptions is the mixture of uniforms (with a background noise component). To be specific, for connected and geometrically compact but otherwise arbitrary subsets $U_1, \ldots, U_p$,  of domain $\mathcal{X}$, we would consider the density function $f(x) \propto \sum_{i = 1}^{p} \pi_i \mathbf{1}(x \in U_i) + \pi_0 \mathbf{1}(x \in \mathcal{X})$. 

[``standard multi-modal densities...''] We do not believe our theory is tight in the case of gaussian mixtures. This is a consequence of the generality of our setup, where the only regularity on the density within $\mathcal{C}$ is imposed by the minimum/maximum density parameters $\lambda_{\sigma}$ and $\Lambda_{\sigma}$. More explicit assumptions about the density -- such as smoothness or unimodality -- within $\mathcal{C}$ would be needed to strengthen our theory in the GMM setup. 

\textbf{Response to Reviewer 2.}

[``weakness in the experiments section...''] We will add more extensive experiments for a camera-ready version.

[``natural set of geometric conditions...''] See above.

[``restructuring and rewriting...''] We thank the reviewer for the suggestion to re-organize, including the suggestion to define well-conditioned density clusters earlier.

\textbf{Response to Reviewer 3. }

[``exact aim...''] See above. We also note that our definition of density upper level sets and recovery of their $\sigma$-expansions is standard in the density clustering literature (e.g. Chaudhuri and Dasgupta).  We apologize for any confusion.

% (e.g. it matches that of Chaudhuri and Dasgupta.)

[``samples from an unknown distribution...''] Included in our supplement is a detailed description of our experimental setup. We will include more experimental details in our main text for a camera-ready version.

[``more than two clusters...''] Yes, the method (and theory) holds for any number of clusters, which is one of the appeals of considering a local clustering approach.

[``PPR on a graph network is not new...''] We agree with the reviewer's points re: novelty of PPR on graphs and recovery of two moons. We feel in fact that the extensive study of PPR on graphs is helpful in the study of statistical properties of PPR, as it reduces our analysis task to showing that the required graph-theoretic properties are satisfied by an appropriate neighborhood graph over point cloud data. Our two moons example was designed to show how, even in a canonical example for spectral algorithms, geometric constraints beyond merely high-density region are required for the successful recovery of one of the moons.
\end{document}